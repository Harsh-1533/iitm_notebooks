{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae88b31",
   "metadata": {},
   "source": [
    "Here are **in-depth notes** on the topic **Greedy Algorithms â€“ Huffman Coding**, based on the lecture by **Prof. Madhavan Mukund** from the PDSA (Programming, Data Structures, and Algorithms using Python) course. Each concept is carefully broken down for clarity and full understanding.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ§  Greedy Algorithms â€“ Huffman Coding (PDSA Notes)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© 1. Introduction to Huffman Coding\n",
    "\n",
    "### âœ‰ï¸ Problem Context: Communication\n",
    "\n",
    "* We send messages in a language (e.g., English, Hindi).\n",
    "* Internally, communication is digital â†’ data transmitted as binary (0s and 1s).\n",
    "* Every **symbol/letter** needs to be **encoded** into binary before transmission.\n",
    "\n",
    "### ğŸ“ Standard Encoding\n",
    "\n",
    "* For 26 letters (Aâ€“Z), we need at least 5 bits because $2^4 = 16 < 26 < 32 = 2^5$.\n",
    "* Fixed-length encoding (5 bits per letter) is simple but inefficient.\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ 2. Motivation for Huffman Coding\n",
    "\n",
    "### ğŸ§  Key Insight:\n",
    "\n",
    "* **Some letters occur more frequently than others.**\n",
    "* Example from Scrabble: 'E' is common, 'Q' and 'Z' are rare.\n",
    "* Idea: Use **shorter codes for frequent letters** and **longer codes for rare ones**.\n",
    "\n",
    "### ğŸš« Limitation of Variable-Length Coding:\n",
    "\n",
    "* Variable-length codes can be **ambiguous**.\n",
    "\n",
    "  * E.g., code string `0101` can be decoded in multiple ways.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… 3. Prefix Codes â€“ The Solution\n",
    "\n",
    "### ğŸ” Prefix-Free Code\n",
    "\n",
    "* A set of codes is **prefix-free** if **no code is a prefix of another**.\n",
    "* This ensures **unambiguous decoding**.\n",
    "* Example: Morse code is not prefix-free (e.g., 'E' = dot, 'A' = dot-dash).\n",
    "\n",
    "### ğŸ“˜ Definition:\n",
    "\n",
    "> A prefix code is a variable-length encoding where no code is a prefix of any other code.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ² 4. Huffman Coding â€“ Core Concepts\n",
    "\n",
    "### ğŸ¯ Goal:\n",
    "\n",
    "Construct a **prefix-free encoding** that **minimizes average number of bits per letter**.\n",
    "\n",
    "### ğŸ“Š Frequency-Based Encoding\n",
    "\n",
    "* Calculate frequency $f(x)$ of each letter from a large corpus.\n",
    "* Encode using binary strings of variable length $E(x)$, such that the **average bits per letter** is minimized:\n",
    "\n",
    "  $$\n",
    "  \\text{Average Bit Length (ABL)} = \\sum_{x \\in \\Sigma} f(x) \\cdot \\text{len}(E(x))\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ 5. Worked Example\n",
    "\n",
    "### Given:\n",
    "\n",
    "| Symbol | Code | Length | Frequency |\n",
    "| ------ | ---- | ------ | --------- |\n",
    "| a      | 11   | 2      | 0.32      |\n",
    "| b      | 10   | 2      | 0.25      |\n",
    "| c      | 001  | 3      | 0.20      |\n",
    "| d      | 000  | 3      | 0.18      |\n",
    "| e      | 01   | 2      | 0.05      |\n",
    "\n",
    "### Average Bit Length:\n",
    "\n",
    "$$\n",
    "0.32 \\cdot 2 + 0.25 \\cdot 2 + 0.20 \\cdot 3 + 0.18 \\cdot 3 + 0.05 \\cdot 2 = 2.25 \\text{ bits}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§® 6. Huffman Tree Structure\n",
    "\n",
    "* **Binary Tree**:\n",
    "\n",
    "  * Symbols are at **leaves**.\n",
    "  * Left edge = 0, Right edge = 1 (or vice versa).\n",
    "  * Encoding of a symbol is the **path from root to leaf**.\n",
    "\n",
    "### âœ¨ Tree Properties\n",
    "\n",
    "1. **Full binary tree**: Each node has 0 or 2 children.\n",
    "2. **Higher frequency = closer to root**.\n",
    "3. **Leaves at deepest level occur in pairs**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” 7. Huffman Tree Construction (Greedy)\n",
    "\n",
    "### ğŸ’¡ Greedy Steps:\n",
    "\n",
    "1. Pick 2 symbols with **lowest frequency**.\n",
    "2. Combine them into a new **composite symbol** with sum frequency.\n",
    "3. Repeat until only 2 symbols remain.\n",
    "4. Build tree **bottom-up**, expand composite nodes back into original symbols.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Construction:\n",
    "\n",
    "Initial frequencies:\n",
    "\n",
    "```\n",
    "a: 0.32, b: 0.25, c: 0.20, d: 0.18, e: 0.05\n",
    "```\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Combine d + e â†’ `de: 0.23`\n",
    "2. Combine `de + c â†’ cde: 0.43`\n",
    "3. Combine `a + b â†’ ab: 0.57`\n",
    "4. Combine `ab + cde â†’ root`\n",
    "\n",
    "Build tree from bottom â†’ top.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ 8. Why is it Optimal?\n",
    "\n",
    "### ğŸ“ Inductive Proof:\n",
    "\n",
    "* Base case: For 2 symbols â†’ assign codes 0 and 1 â†’ trivially optimal.\n",
    "* Inductive step:\n",
    "\n",
    "  * Combine least frequent x and y to form x+y.\n",
    "  * Build optimal code for new alphabet (kâˆ’1 size).\n",
    "  * Expand x+y into x and y at one extra depth.\n",
    "  * Show that average length increases by exactly $f(x) + f(y)$, **no worse than any other tree**.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ 9. Implementation Details\n",
    "\n",
    "### ğŸš€ Efficiency:\n",
    "\n",
    "* Naive version: O(nÂ²)\n",
    "* Optimized version:\n",
    "\n",
    "  * Use a **min-heap (priority queue)** to pick least frequent symbols.\n",
    "  * Operations take $O(\\log n)$\n",
    "  * Overall time: **$O(n \\log n)$**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒŸ 10. Why is it Greedy?\n",
    "\n",
    "* At every step, **locally** choose the two smallest frequencies to combine.\n",
    "* Never backtrack or revise this choice.\n",
    "* Globally optimal due to the inductive proof.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  11. Historical Context\n",
    "\n",
    "* Developed in the context of **Information Theory** by **Claude Shannon**.\n",
    "* **Shannon-Fano Code** was an earlier, non-optimal approach.\n",
    "* **David Huffman**, a student under Fano at MIT, invented Huffman Coding as part of a **class assignment**.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary of Key Points\n",
    "\n",
    "| Concept              | Explanation                                           |\n",
    "| -------------------- | ----------------------------------------------------- |\n",
    "| Fixed-Length Code    | Same bits for every symbol                            |\n",
    "| Variable-Length Code | Shorter bits for frequent, longer for rare symbols    |\n",
    "| Prefix Code          | No code is prefix of another                          |\n",
    "| Huffman Tree         | Binary tree where leaves are symbols, path gives code |\n",
    "| Greedy Choice        | Always combine lowest frequency symbols               |\n",
    "| Optimality           | Proven by induction on size of alphabet               |\n",
    "| Time Complexity      | $O(n \\log n)$ using heap                              |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
