{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51738f62",
   "metadata": {},
   "source": [
    "## üìò Supervised Learning: Regression ‚Äì Notation\n",
    "\n",
    "### üî¢ Mathematical Symbols and Notations\n",
    "\n",
    "- **‚Ñù**: Set of **real numbers**  \n",
    "  ‚Ñù = all numbers on the number line, including decimals, fractions, etc.\n",
    "\n",
    "- **‚Ñù‚Çä**: Set of **positive real numbers**  \n",
    "  Includes only real numbers greater than 0\n",
    "\n",
    "- **‚Ñù·µà**: A **d-dimensional vector** of real numbers  \n",
    "  For example, in 3D: x ‚àà ‚Ñù¬≥ means x = [x‚ÇÅ, x‚ÇÇ, x‚ÇÉ]\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Vectors and Coordinates\n",
    "\n",
    "- **x**: A vector (list of numbers), e.g., `x = [3, 5, 1]`\n",
    "\n",
    "- **x‚±º**: The **j·µó ∞ coordinate** (element) of the vector x  \n",
    "  For example, if `x = [3, 5, 1]`, then `x‚ÇÇ = 5`\n",
    "\n",
    "- **‚Äñx‚Äñ**: The **length (magnitude)** of the vector x  \n",
    "  It is calculated as: ‚Äñx‚Äñ = ‚àö(x‚ÇÅ¬≤ + x‚ÇÇ¬≤ + ... + x_d¬≤)\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Collection of Vectors\n",
    "\n",
    "- **x¬π, x¬≤, ..., x‚Åø**: A **collection of n vectors**  \n",
    "  Example: If n = 3 and d = 2, then we may have:\n",
    "  - x¬π = [1, 2]\n",
    "  - x¬≤ = [3, 4]\n",
    "  - x¬≥ = [5, 6]\n",
    "\n",
    "- **x‚±º‚Å±**: The **j·µó ∞ coordinate of the i·µó ∞ vector**  \n",
    "  Example: x‚ÇÇ¬≥ = 6 ‚Üí (2nd element of 3rd vector)\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Other Notations\n",
    "\n",
    "- **(x‚ÇÅ)¬≤**: Square of the **first coordinate** of the vector x  \n",
    "  If x = [4, 3, 2], then (x‚ÇÅ)¬≤ = 4¬≤ = 16\n",
    "\n",
    "- **1(condition)**: This is called the **indicator function**.  \n",
    "  It returns 1 if the condition is **true**, otherwise 0.  \n",
    "  Example:\n",
    "    - 1(2 is even) = 1\n",
    "    - 1(2 is odd) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc6220",
   "metadata": {},
   "source": [
    "## üìò Supervised Learning ‚Äì Regression\n",
    "\n",
    "### üè† Example Problem\n",
    "\n",
    "**Goal:** Predict **house price** from features such as:\n",
    "- Number of rooms\n",
    "- Area (sq. ft.)\n",
    "- Distance to city center\n",
    "\n",
    "This is a **regression** task because the target output (house price) is a real number.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Training Data\n",
    "\n",
    "Training data is a collection of **input-output pairs**:\n",
    "$$(x^1, y^1), (x^2, y^2), \\dots, (x^n, y^n)$$\n",
    "\n",
    "Where:\n",
    "- $x^i \\in \\mathbb{R}^d$: the **i-th input vector**, containing `d` features (e.g., rooms, area, distance)\n",
    "- $y^i \\in \\mathbb{R}$: the **i-th output**, a real number (house price)\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Model and Output\n",
    "\n",
    "The learning algorithm outputs a **model** function:\n",
    "$$f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$$\n",
    "\n",
    "This function maps input vectors to predicted outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìâ Loss Function\n",
    "\n",
    "To measure prediction error, we use **Mean Squared Error (MSE)**:\n",
    "$${\\text{Loss}} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( f(x^i) - y^i \\right)^2$$\n",
    "\n",
    "This penalizes the square of the difference between the predicted value and the actual output.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Linear Regression Model\n",
    "\n",
    "We assume a linear function:\n",
    "$$f(x) = \\mathbf{w}^\\top x + b = \\sum_{j=1}^{d} w_j x_j + b$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{w}$ = weight vector (learned by the model)\n",
    "- $x$ = input vector\n",
    "- $b$ = bias/intercept term\n",
    "\n",
    "This is a **linear regression model**, where the prediction is a weighted sum of input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d8944",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "--- \n",
    "\n",
    "# Notes from transcript\n",
    "\n",
    "\n",
    "# Machine Learning Foundations: Supervised Learning\n",
    "\n",
    "Hello, everyone, and welcome to another lecture on **Machine Learning Foundations**.  \n",
    "In this lecture, we will take a deeper dive into one main paradigm of machine learning, which is **supervised learning**.\n",
    "\n",
    "There are several supervised learning tasks, but the two most important tasks that are encountered in machine learning are **regression** and **classification**. In fact, supervised learning is the most common paradigm of machine learning. When someone says \"machine learning,\" they typically mean supervised learning unless they specify otherwise (e.g., unsupervised learning, reinforcement learning).\n",
    "\n",
    "---\n",
    "\n",
    "## Notation\n",
    "\n",
    "We will use some mathematical notation which will be needed for the rest of the lecture.\n",
    "\n",
    "- **\\(\\mathbb{R}\\)**: the set of real numbers.  \n",
    "  Examples: 2.3, \\(\\sqrt{\\pi}\\), -7.6 are real numbers.\n",
    "\n",
    "- **\\(\\mathbb{R}^d\\)**: the set of all \\(d\\)-dimensional vectors of real numbers.  \n",
    "  Example: an element in \\(\\mathbb{R}^3\\) might be \\((3.6, 5.2, -1.8)\\).\n",
    "\n",
    "- We denote a vector by \\( \\mathbf{x} \\), and \\( x_j \\) denotes the \\(j\\)-th coordinate of the vector.\n",
    "\n",
    "- The **norm** (or length) of a vector \\( \\mathbf{x} \\) is denoted as \\( \\|\\mathbf{x}\\| \\), which is the Euclidean length. For example, for \\( \\mathbf{x} \\in \\mathbb{R}^3 \\):\n",
    "\n",
    "\\[\n",
    "\\|\\mathbf{x}\\|^2 = x_1^2 + x_2^2 + x_3^2,\n",
    "\\quad\n",
    "\\|\\mathbf{x}\\| = \\sqrt{x_1^2 + x_2^2 + x_3^2}\n",
    "\\]\n",
    "\n",
    "- When working with a collection of vectors, we use **superscripts** for indexing different vectors and **subscripts** for elements in a vector. For example, \\( x_i \\) is the \\(i\\)-th vector, and \\( x_{ij} \\) is the \\(j\\)-th coordinate of the \\(i\\)-th vector.\n",
    "\n",
    "Example:  \n",
    "If\n",
    "\n",
    "\\[\n",
    "\\mathbf{x}^1 = (1, 2, 3), \\quad \\mathbf{x}^2 = (1, 1, 1), \\quad \\mathbf{x}^3 = (7, 7, 8)\n",
    "\\]\n",
    "\n",
    "then \\( x_{32} = 7 \\) (the second coordinate of the third vector).\n",
    "\n",
    "- To denote powers, we use parentheses to avoid confusion. For example, \\( (x_1)^2 \\) is the square of the first coordinate of the vector \\( \\mathbf{x} \\).\n",
    "\n",
    "- We also use **indicator variables** denoted by \\( \\mathbf{1}\\{\\text{condition}\\} \\), which equals 1 if the condition is true, and 0 otherwise.  \n",
    "For example:  \n",
    "\\[\n",
    "\\mathbf{1}\\{2 \\text{ is even}\\} = 1, \\quad \\mathbf{1}\\{2 \\text{ is odd}\\} = 0\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## Supervised Learning Paradigm\n",
    "\n",
    "At its core, **supervised learning** can be thought of as **curve-fitting**. You have a set of points \\((\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\ldots, (\\mathbf{x}_n, y_n)\\), where \\(\\mathbf{x}_i \\in \\mathbb{R}^d\\) are input vectors and \\(y_i\\) are labels.\n",
    "\n",
    "The goal is to find a model \\( f: \\mathbb{R}^d \\to \\mathcal{Y} \\) such that:\n",
    "\n",
    "\\[\n",
    "f(\\mathbf{x}_i) \\approx y_i\n",
    "\\]\n",
    "\n",
    "This means the function \\(f\\) should produce outputs close to the labels for each input vector.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Regression Problem\n",
    "\n",
    "Suppose you want to predict the price of a house from features such as number of rooms, area, and distance to metro.  \n",
    "- Each house is represented by a 3D vector:  \n",
    "\\[\n",
    "\\mathbf{x} = (\\text{number of rooms}, \\text{area}, \\text{distance})\n",
    "\\]  \n",
    "- The label \\(y\\) is the house price (a real number).\n",
    "\n",
    "The goal of the learning algorithm is to find a function \\(f : \\mathbb{R}^3 \\to \\mathbb{R}\\) such that:\n",
    "\n",
    "\\[\n",
    "f(\\mathbf{x}_i) \\approx y_i\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "To evaluate how well the model \\(f\\) performs, we use a **loss function** measuring the deviation:\n",
    "\n",
    "\\[\n",
    "\\text{Loss}(f) = \\frac{1}{n} \\sum_{i=1}^n (f(\\mathbf{x}_i) - y_i)^2\n",
    "\\]\n",
    "\n",
    "- The loss is always non-negative.\n",
    "- The best model has a loss of 0, meaning \\( f(\\mathbf{x}_i) = y_i \\) for all \\(i\\).\n",
    "\n",
    "---\n",
    "\n",
    "### Linear Models\n",
    "\n",
    "A common model form is a **linear model**:\n",
    "\n",
    "\\[\n",
    "f(\\mathbf{x}) = \\mathbf{w}^\\top \\mathbf{x} + b = w_1 x_1 + w_2 x_2 + \\cdots + w_d x_d + b\n",
    "\\]\n",
    "\n",
    "- \\(w_1, w_2, \\ldots, w_d, b\\) are parameters learned from data.\n",
    "- For house price prediction, it might look like:\n",
    "\n",
    "\\[\n",
    "\\text{price} = w_1 \\times \\text{rooms} + w_2 \\times \\text{area} + w_3 \\times \\text{distance} + b\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Simple Example with One-Dimensional Input\n",
    "\n",
    "Suppose the input dimension \\(d=1\\) and the training data points are:\n",
    "\n",
    "\\[\n",
    "x: 1, 2, 3, 6, 7\n",
    "\\]\n",
    "\\[\n",
    "y: 2.1, 3.9, 6.2, 11.5, 13.9\n",
    "\\]\n",
    "\n",
    "Plotting these points on the \\(xy\\)-plane helps visualize the data.\n",
    "\n",
    "Let's consider two candidate models:\n",
    "\n",
    "- \\( f(x) = 2x \\)\n",
    "- \\( g(x) = x + 3 \\)\n",
    "\n",
    "Evaluate the predictions:\n",
    "\n",
    "| \\(x\\) | 1 | 2 | 3 | 6 | 7 |\n",
    "|-------|---|---|---|---|---|\n",
    "| \\(f(x)\\) | 2 | 4 | 6 | 12 | 14 |\n",
    "| \\(g(x)\\) | 4 | 5 | 6 | 9 | 10 |\n",
    "\n",
    "Calculate the losses for each and choose the model with the smaller loss.\n",
    "\n",
    "---\n",
    "\n",
    "This concludes the foundational overview of supervised learning, regression, and the notation used.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
