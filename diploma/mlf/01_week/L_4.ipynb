{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36983b2b",
   "metadata": {},
   "source": [
    "# üß† Supervised Learning: Classification\n",
    "Training data: {(x1, y1), (x2, y2), ..., (x\", y\")}\n",
    "\n",
    "x¬≤ ‚àà Rd, y¬≤ ‚àà {+1,-1}\n",
    "\n",
    "Algorithm outputs a model f : Rd‚Üí{+1,-1}\n",
    "\n",
    "Loss = 11(f(x¬≤) ‚â† y¬≤) 1 n n\n",
    "\n",
    "f(x) = sign(wx+b)\n",
    "\n",
    "## üìå Goal\n",
    "\n",
    "> Predict if the **number of rooms > 3** from **area** and **price** of a house.\n",
    "\n",
    "This is a **binary classification** problem where:\n",
    "- Output (`y`) is either `+1` (Yes) or `-1` (No)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Training Data\n",
    "\n",
    "We use pairs of feature vectors and labels:\n",
    "\n",
    "$$\n",
    "\\left\\{ (x^1, y^1), (x^2, y^2), \\dots, (x^n, y^n) \\right\\}\n",
    "$$\n",
    "\n",
    "- \\( x^i \\in \\mathbb{R}^d \\): each feature vector (e.g., area, price)\n",
    "- \\( y^i \\in \\{+1, -1\\} \\): binary label indicating the class\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Model Function\n",
    "\n",
    "The model is a **linear classifier**:\n",
    "\n",
    "$$\n",
    "f : \\mathbb{R}^d \\rightarrow \\{+1, -1\\}\n",
    "$$\n",
    "\n",
    "It uses the **sign function** to make predictions:\n",
    "\n",
    "$$\n",
    "f(x) = \\text{sign}(\\mathbf{w}^\\top \\mathbf{x} + b)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( \\mathbf{w} \\): weight vector  \n",
    "- \\( b \\): bias term  \n",
    "- \\( \\text{sign}(z) = \\begin{cases}\n",
    "+1 & \\text{if } z > 0 \\\\\n",
    "-1 & \\text{otherwise}\n",
    "\\end{cases} \\)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Loss Function (0-1 Loss)\n",
    "\n",
    "To evaluate model performance:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}(f(x^i) \\neq y^i)\n",
    "$$\n",
    "\n",
    "- It counts how many predictions are incorrect.  \n",
    "- \\( \\mathbf{1}(\\cdot) \\) is the **indicator function**, which returns 1 if the condition is true, otherwise 0.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Intuition\n",
    "\n",
    "- We're drawing a **decision boundary (line/hyperplane)** to separate two classes.\n",
    "- Works well when data is **linearly separable**.\n",
    "- Outputs **only class labels** (`+1` or `-1`), not probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91b3ab",
   "metadata": {},
   "source": [
    "## Evaluating Learned Models : Test Data\n",
    "   - Learning algorithm uses training data $(x^1, y^1), ........, (x^n, y^n)$ to get model f.\n",
    "   - But evaluating the learned model must not be done on the training data itself.\n",
    "   - Use test data that is not in the training data for model evaluation.\n",
    "\n",
    "## Model Selection  : Validation Data\n",
    "   - Learning algorithms just find the \"best\" model in the collection of models given by the human.\n",
    "   - How to find the right collection of models?\n",
    "   - This is called model selection, and it is done by using another subset of data called **validation data** that is distinct from train and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e4d99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226df7e2",
   "metadata": {},
   "source": [
    "# üìò Machine Learning Foundations ‚Äì Lecture: Classification\n",
    "\n",
    "Welcome to another lecture on **Machine Learning Foundations**.\n",
    "\n",
    "In the last lecture, we introduced the **supervised learning paradigm** and the **regression learning problem**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Today's Topic: Classification\n",
    "\n",
    "We'll now explore the **classification problem** and look at a few examples.\n",
    "\n",
    "### üîç Example:\n",
    "Suppose you're given the `area` and `price` of a house, and you want to **predict whether the number of rooms** is:\n",
    "- `> 3` (more than 3)\n",
    "- `‚â§ 3` (3 or fewer)\n",
    "\n",
    "This is a **classification problem**, because the prediction output is **categorical** (either of two labels).\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Training Data Format\n",
    "\n",
    "Just like regression, we use:\n",
    "- Inputs: \\( \\mathbf{x}_i \\in \\mathbb{R}^d \\)\n",
    "- Labels: \\( y_i \\in \\{+1, -1\\} \\)\n",
    "\n",
    "> ‚ö†Ô∏è Unlike regression (where \\( y_i \\in \\mathbb{R} \\)), here the outputs are just two discrete values.\n",
    "\n",
    "The **model output** is:\n",
    "\\[\n",
    "f: \\mathbb{R}^d \\rightarrow \\{+1, -1\\}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Evaluating a Classification Model\n",
    "\n",
    "The goal is:\n",
    "\\[\n",
    "f(\\mathbf{x}_i) = y_i \\quad \\text{for all } i\n",
    "\\]\n",
    "\n",
    "In reality, this might not always happen.\n",
    "\n",
    "### üìâ Loss Function: 0-1 Loss\n",
    "\\[\n",
    "\\text{Loss}(f) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}[f(\\mathbf{x}_i) \\ne y_i]\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mathbb{I}[\\cdot] \\) is an indicator function (1 if true, 0 otherwise)\n",
    "- The loss counts the **fraction of misclassified points**\n",
    "\n",
    "---\n",
    "\n",
    "## üìè Linear Classifiers\n",
    "\n",
    "In regression, we had:\n",
    "\\[\n",
    "f(\\mathbf{x}) = \\mathbf{w}^\\top \\mathbf{x} + b\n",
    "\\]\n",
    "\n",
    "But for classification:\n",
    "\\[\n",
    "f(\\mathbf{x}) = \\text{sign}(\\mathbf{w}^\\top \\mathbf{x} + b)\n",
    "\\]\n",
    "\n",
    "This is called a **linear separator**. It maps inputs to either \\( +1 \\) or \\( -1 \\).\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Simple 2D Example\n",
    "\n",
    "Let \\( d = 2 \\). We have 6 data points:\n",
    "\n",
    "### üìå Data Points:\n",
    "| Point | Coordinates   | Label  |\n",
    "|-------|---------------|--------|\n",
    "| x‚ÇÅ    | (0, 0)        | +1     |\n",
    "| x‚ÇÇ    | (1, 0)        | +1     |\n",
    "| x‚ÇÉ    | (0, 1)        | +1     |\n",
    "| x‚ÇÑ    | (4, 4)        | -1     |\n",
    "| x‚ÇÖ    | (3, 4)        | -1     |\n",
    "| x‚ÇÜ    | (4, 3)        | -1     |\n",
    "\n",
    "### üñºÔ∏è Visualization (Rough Description):\n",
    "- Red points: positive class\n",
    "- Blue points: negative class\n",
    "\n",
    "All red points are in the bottom-left, and all blue points are in the top-right of the 2D plane.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Two Models to Compare\n",
    "\n",
    "Let's define two classifiers:\n",
    "\n",
    "### Model f:\n",
    "\\[\n",
    "f(\\mathbf{x}) = \\text{sign}(2 - x_1)\n",
    "\\]\n",
    "\n",
    "### Model g:\n",
    "\\[\n",
    "g(\\mathbf{x}) = \\text{sign}(x_1 - 2x_2)\n",
    "\\]\n",
    "\n",
    "We will compute the loss for each.\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Evaluate Model f\n",
    "\n",
    "Apply \\( f(\\mathbf{x}) = \\text{sign}(2 - x_1) \\) to each point:\n",
    "\n",
    "| x     | f(x)         | y    | Correct? |\n",
    "|-------|--------------|------|----------|\n",
    "| (0,0) | +1           | +1   | ‚úÖ       |\n",
    "| (1,0) | +1           | +1   | ‚úÖ       |\n",
    "| (0,1) | +1           | +1   | ‚úÖ       |\n",
    "| (4,4) | -1           | -1   | ‚úÖ       |\n",
    "| (3,4) | -1           | -1   | ‚úÖ       |\n",
    "| (4,3) | -1           | -1   | ‚úÖ       |\n",
    "\n",
    "üü¢ All predictions correct ‚Üí **Loss = 0**\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Evaluate Model g\n",
    "\n",
    "Apply \\( g(\\mathbf{x}) = \\text{sign}(x_1 - 2x_2) \\):\n",
    "\n",
    "| x     | g(x)         | y    | Correct? |\n",
    "|-------|--------------|------|----------|\n",
    "| (0,0) | +1           | +1   | ‚úÖ       |\n",
    "| (1,0) | +1           | +1   | ‚úÖ       |\n",
    "| (0,1) | -1           | +1   | ‚ùå       |\n",
    "| (4,4) | -1           | -1   | ‚úÖ       |\n",
    "| (3,4) | -1           | -1   | ‚úÖ       |\n",
    "| (4,3) | -1           | -1   | ‚úÖ       |\n",
    "\n",
    "üî¥ One mistake ‚Üí **Loss = 1/6**\n",
    "\n",
    "---\n",
    "\n",
    "## üèÅ Conclusion\n",
    "\n",
    "- **f** has lower loss ‚Üí learning algorithm will **prefer model f**\n",
    "- In general, the algorithm learns the best function from all possible classifiers\n",
    "- For visualization, the **input space is split into regions**:\n",
    "  - Region where \\( f(\\mathbf{x}) = +1 \\)\n",
    "  - Region where \\( f(\\mathbf{x}) = -1 \\)\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Key Takeaway**:\n",
    "Classification involves predicting labels from a finite set. The loss function typically measures the number (or fraction) of misclassifications. Linear separators like \\( \\text{sign}(\\mathbf{w}^\\top \\mathbf{x} + b) \\) are a powerful and interpretable model in simple classification problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591cfd1",
   "metadata": {},
   "source": [
    "## üìÅ Training, Validation, and Test Data\n",
    "\n",
    "In supervised machine learning, we split our dataset into three parts:\n",
    "\n",
    "---\n",
    "\n",
    "### üîß 1. Training Data\n",
    "\n",
    "- **Used to train the model**\n",
    "- The model learns patterns, weights, and relationships from this data\n",
    "- The training process **minimizes loss** on this data\n",
    "- **Risk**: If the model only learns from training data, it might memorize it (overfitting)\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ 2. Validation Data\n",
    "\n",
    "- **Used during training** to tune the model\n",
    "- Helps in choosing the **best model or hyperparameters**\n",
    "- Not used to update the model directly\n",
    "- Helps detect **overfitting**: if training accuracy is high but validation accuracy is low, the model might not generalize well\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ 3. Test Data\n",
    "\n",
    "- **Used only after training and model selection are complete**\n",
    "- It measures the **final performance** of the model on **unseen data**\n",
    "- Helps us understand how the model will perform in the real world\n",
    "- We **never train or tune** the model using test data\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary Table\n",
    "\n",
    "| Dataset        | Used For                            | Model Sees It? | Purpose                         |\n",
    "|----------------|-------------------------------------|----------------|----------------------------------|\n",
    "| Training       | Learning model parameters (weights) | ‚úÖ Yes         | Learn patterns                  |\n",
    "| Validation     | Tuning model & hyperparameters      | ‚úÖ Yes         | Check generalization during training |\n",
    "| Test           | Final evaluation                    | ‚ùå No          | Check true generalization       |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **Important**:\n",
    "- Never use test data to make training decisions.\n",
    "- Validation data can be used multiple times while tuning.\n",
    "- Test data should be used **only once** after everything is finalized.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
