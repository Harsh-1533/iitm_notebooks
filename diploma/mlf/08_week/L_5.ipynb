{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f8db2e",
   "metadata": {},
   "source": [
    "Here are detailed notes for **L8.5: Basic Algorithm for Unconstrained Optimization ‚Äì Gradient Descent**, covering each and every topic mentioned in the transcript:\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Lecture 8.5: Basic Algorithm for Unconstrained Optimization ‚Äì Gradient Descent\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Goal\n",
    "\n",
    "To minimize an unconstrained objective function:\n",
    "\n",
    "$$\n",
    "\\min_{x \\in \\mathbb{R}} f(x)\n",
    "$$\n",
    "\n",
    "We want a general-purpose algorithm that, given any differentiable function $f$, iteratively finds a point that minimizes it.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Gradient Descent Algorithm (1D)\n",
    "\n",
    "### **Algorithm Summary**\n",
    "\n",
    "1. **Initialize**:\n",
    "   Choose any starting point $x_0 \\in \\mathbb{R}$\n",
    "\n",
    "2. **For** $t = 0, 1, 2, \\dots$\n",
    "\n",
    "   $$\n",
    "   x_{t+1} = x_t - \\eta_t f'(x_t)\n",
    "   $$\n",
    "\n",
    "   where the **step size** (learning rate) is chosen as:\n",
    "\n",
    "   $$\n",
    "   \\eta_t = \\frac{1}{t+1}\n",
    "   $$\n",
    "\n",
    "This is the **Gradient Descent Algorithm** for 1D unconstrained optimization.\n",
    "\n",
    "---\n",
    "\n",
    "## üìõ Why is it Called \"Gradient Descent\"?\n",
    "\n",
    "* The **gradient** is the generalization of the derivative to higher dimensions.\n",
    "* The word **descent** refers to the fact that we move in the direction that decreases the function value: the **negative derivative**.\n",
    "\n",
    "This is a **first-order optimization algorithm**, as it uses only first-order information (the gradient or derivative of $f$).\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Generalization to Higher Dimensions\n",
    "\n",
    "In higher dimensions ($x \\in \\mathbb{R}^d$):\n",
    "\n",
    "* Replace the derivative $f'(x)$ with the **gradient** $\\nabla f(x)$\n",
    "* The update rule becomes:\n",
    "\n",
    "  $$\n",
    "  x_{t+1} = x_t - \\eta_t \\nabla f(x_t)\n",
    "  $$\n",
    "\n",
    "The algorithm works similarly for **vector-valued inputs**, as long as the function is differentiable.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Nature of Gradient Descent\n",
    "\n",
    "* **Iterative**: Improves the guess with each step $t$\n",
    "* **Only requires ability to compute derivative**\n",
    "* **Simple to implement** and widely used in practice\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Convergence Properties\n",
    "\n",
    "### **Key Property**: If $\\eta_t = \\frac{1}{t+1}$, then:\n",
    "\n",
    "* The algorithm **converges**: i.e., oscillations are avoided\n",
    "* It **converges to a local minimum** (not necessarily the global one)\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ Local vs Global Minimum\n",
    "\n",
    "### üü• Global Minimum:\n",
    "\n",
    "* A point $x^\\star$ is a **global minimum** if:\n",
    "\n",
    "  $$\n",
    "  f(x^\\star) \\leq f(x) \\quad \\forall x \\in \\mathbb{R}\n",
    "  $$\n",
    "\n",
    "### üü¶ Local Minimum:\n",
    "\n",
    "* A point $\\hat{x}$ is a **local minimum** if:\n",
    "\n",
    "  $$\n",
    "  \\exists \\epsilon > 0 \\text{ such that } f(\\hat{x}) \\leq f(x), \\forall x \\in (\\hat{x} - \\epsilon, \\hat{x} + \\epsilon)\n",
    "  $$\n",
    "* The function value is the lowest **in a small neighborhood**, not necessarily everywhere.\n",
    "\n",
    "### üìà Local Maximum:\n",
    "\n",
    "Defined similarly, but with the inequality sign reversed:\n",
    "\n",
    "$$\n",
    "f(\\hat{x}) \\geq f(x) \\quad \\forall x \\in (\\hat{x} - \\epsilon, \\hat{x} + \\epsilon)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Why Gradient Descent Only Finds Local Minima\n",
    "\n",
    "* If you start at a point $x_0$, GD will follow the **negative gradient** direction\n",
    "* It will stop when the derivative (or gradient) becomes **zero**\n",
    "* If this happens at a **local minimum**, the algorithm will **get stuck** there\n",
    "* It **cannot climb out** of the valley to reach a better minimum beyond, because it only moves based on local slope\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Illustrative Example\n",
    "\n",
    "Suppose $f(x)$ is a \"wiggly\" function like:\n",
    "\n",
    "![wiggly\\_function](conceptual)\n",
    "\n",
    "* There are many **local minima** (marked in blue)\n",
    "* Only one **global minimum** (marked in red)\n",
    "* Depending on where you start ($x_0$), gradient descent may converge to any of the local minima\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùó Important Observations\n",
    "\n",
    "1. **Gradient Descent is Not Guaranteed to Find Global Minima**\n",
    "\n",
    "   * Without assumptions on $f$, no algorithm can guarantee global minimum\n",
    "\n",
    "2. **But in Practice: Local Minima May Be Good Enough**\n",
    "\n",
    "   * Especially in ML, **local minima are often as good as global ones**\n",
    "   * For many problems, **every local minimum is also a global minimum**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Example: $f(x) = (x - 5)^2$\n",
    "\n",
    "* This is a **convex function**\n",
    "* It has **one** local minimum, which is also the **global minimum**\n",
    "* Gradient Descent converges to 5, no matter the starting point\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Convex Functions\n",
    "\n",
    "* A function is **convex** if **every local minimum is also a global minimum**\n",
    "* Gradient Descent performs **optimally** on convex functions\n",
    "* Most loss functions used in machine learning are **convex**\n",
    "\n",
    "---\n",
    "\n",
    "## üîÆ Looking Ahead: Open Questions\n",
    "\n",
    "1. **Why is $-f'(x)$** a good direction to move in?\n",
    "\n",
    "   * We‚Äôll analyze its **geometric** and **intuitive** justification\n",
    "   * Leads us to more advanced optimization methods\n",
    "\n",
    "2. **What if constraints are present?**\n",
    "\n",
    "   * We'll extend this to **constrained optimization** later\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "| Concept        | Description                                                |\n",
    "| -------------- | ---------------------------------------------------------- |\n",
    "| Objective      | Minimize $f(x)$ with no constraints                        |\n",
    "| Algorithm      | Gradient Descent                                           |\n",
    "| Update Rule    | $x_{t+1} = x_t - \\eta_t f'(x_t)$, $\\eta_t = \\frac{1}{t+1}$ |\n",
    "| Works for      | Any differentiable function $f$                            |\n",
    "| Converges to   | A **local minimum** (not necessarily global)               |\n",
    "| Limitations    | Can get stuck at local minima                              |\n",
    "| Useful when    | Function is **convex** ‚Äì local = global minimum            |\n",
    "| Real-world use | Extremely effective in many ML applications                |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
