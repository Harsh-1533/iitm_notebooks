{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13343377",
   "metadata": {},
   "source": [
    "Hereâ€™s your **in-depth Week 4 Study Notes**, complete with key concepts and one example per topic for deeper understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“˜ Week 4 â€” In-Depth Study Notes: Eigenvalues, Diagonalization & Polynomial Regression\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 1. **Eigenvalues and Eigenvectors**\n",
    "\n",
    "#### ðŸ”¹ Definition:\n",
    "\n",
    "For a square matrix $A$, a nonzero vector $x$ is an **eigenvector** if:\n",
    "\n",
    "$$\n",
    "A x = \\lambda x\n",
    "$$\n",
    "\n",
    "Here, $\\lambda$ is the **eigenvalue** corresponding to eigenvector $x$.\n",
    "\n",
    "#### ðŸ”¹ Characteristic Polynomial:\n",
    "\n",
    "To find eigenvalues:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Find eigenvalues:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) =\n",
    "\\det\\begin{bmatrix}\n",
    "2 - \\lambda & 1 \\\\\n",
    "1 & 2 - \\lambda\n",
    "\\end{bmatrix}\n",
    "= (2 - \\lambda)^2 - 1 = \\lambda^2 - 4\\lambda + 3\n",
    "$$\n",
    "\n",
    "Solving:\n",
    "\n",
    "$$\n",
    "\\lambda^2 - 4\\lambda + 3 = 0 \\Rightarrow \\lambda = 1, 3\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 2. **Trace and Determinant via Eigenvalues**\n",
    "\n",
    "* **Trace** $\\text{tr}(A)$ = Sum of eigenvalues\n",
    "* **Determinant** $\\det(A)$ = Product of eigenvalues\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "For matrix $A$ above:\n",
    "\n",
    "* Eigenvalues = 1, 3\n",
    "* Trace = $1 + 3 = 4$\n",
    "* Determinant = $1 \\times 3 = 3$\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3. **Diagonalization**\n",
    "\n",
    "#### ðŸ”¹ Definition:\n",
    "\n",
    "A matrix $A$ is **diagonalizable** if:\n",
    "\n",
    "$$\n",
    "A = P \\Lambda P^{-1}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\Lambda$ is a diagonal matrix of eigenvalues\n",
    "* Columns of $P$ are eigenvectors\n",
    "\n",
    "#### ðŸ”¹ When is a matrix diagonalizable?\n",
    "\n",
    "* If it has **n** linearly independent eigenvectors (for $n \\times n$ matrix)\n",
    "* Always true if eigenvalues are **distinct**\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "4 & 1 \\\\\n",
    "0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Find eigenvalues:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = (4 - \\lambda)(2 - \\lambda)\n",
    "\\Rightarrow \\lambda = 4, 2\n",
    "$$\n",
    "\n",
    "Since eigenvalues are distinct â†’ $A$ is diagonalizable.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 4. **Real Symmetric and Projection Matrices**\n",
    "\n",
    "#### ðŸ”¹ Real Symmetric Matrices:\n",
    "\n",
    "* Always **diagonalizable**\n",
    "* Always have **real** eigenvalues\n",
    "* Eigenvectors for distinct eigenvalues are **orthogonal**\n",
    "\n",
    "#### ðŸ”¹ Projection Matrix:\n",
    "\n",
    "* A matrix $P$ such that $P^2 = P$\n",
    "* Eigenvalues are **0** and **1**\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "P = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* $P^2 = P$\n",
    "* Eigenvalues: $\\lambda = 1, 0$\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 5. **Matrix Powers and Eigenvalues**\n",
    "\n",
    "If eigenvalues of $A$ are $\\lambda_i$,\n",
    "then eigenvalues of $A^k$ are $\\lambda_i^k$.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "If $A$'s eigenvalues = $-1, 3, 4$,\n",
    "Then eigenvalues of $A^2$ = $1, 9, 16$\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 6. **Fibonacci Sequence via Diagonalization**\n",
    "\n",
    "The Fibonacci recurrence:\n",
    "\n",
    "$$\n",
    "F_n = F_{n-1} + F_{n-2}\n",
    "$$\n",
    "\n",
    "Can be represented by:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "F_n \\\\\n",
    "F_{n-1}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}^n\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Diagonalizing this matrix gives the **closed-form** (Binetâ€™s Formula):\n",
    "\n",
    "$$\n",
    "F_n = \\frac{1}{\\sqrt{5}} \\left( \\left( \\frac{1 + \\sqrt{5}}{2} \\right)^n -\n",
    "\\left( \\frac{1 - \\sqrt{5}}{2} \\right)^n \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "Approximate $F_{110}$ using:\n",
    "\n",
    "$$\n",
    "F_n \\approx \\frac{1}{\\sqrt{5}} \\left( \\frac{1 + \\sqrt{5}}{2} \\right)^n\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 7. **Polynomial Regression (Least Squares Fitting)**\n",
    "\n",
    "#### ðŸ”¹ Goal:\n",
    "\n",
    "Fit a polynomial:\n",
    "\n",
    "$$\n",
    "y = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given data $(x_i, y_i)$, set up:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "x_1^2 & x_1 & 1 \\\\\n",
    "x_2^2 & x_2 & 1 \\\\\n",
    "\\cdots & \\cdots & \\cdots\n",
    "\\end{bmatrix}, \\quad y = \\begin{bmatrix}\n",
    "y_1 \\\\ y_2 \\\\ \\cdots\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Solve:\n",
    "\n",
    "$$\n",
    "\\theta = (A^T A)^{-1} A^T y\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "| x   | y   |\n",
    "| --- | --- |\n",
    "| 0   | 0   |\n",
    "| 1.3 | 1.5 |\n",
    "| 4   | 1.2 |\n",
    "\n",
    "Set up:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 0 & 1 \\\\\n",
    "1.69 & 1.3 & 1 \\\\\n",
    "16 & 4 & 1\n",
    "\\end{bmatrix},\\quad y = \\begin{bmatrix} 0 \\\\ 1.5 \\\\ 1.2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Using least squares:\n",
    "\n",
    "$$\n",
    "\\theta = \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} = \\text{coefficients}\n",
    "\\Rightarrow y \\approx -0.316x^2 + 1.56x\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary Checklist\n",
    "\n",
    "| Topic                               | Must Know                                    |\n",
    "| ----------------------------------- | -------------------------------------------- |\n",
    "| **Eigenvalues/Vectors**             | Characteristic polynomial, geometric meaning |\n",
    "| **Trace/Determinant**               | Use eigenvalues to compute                   |\n",
    "| **Diagonalization**                 | When and how to diagonalize                  |\n",
    "| **Symmetric & Projection Matrices** | Special properties and their implications    |\n",
    "| **Matrix Powers**                   | Power of eigenvalues                         |\n",
    "| **Fibonacci via Diagonalization**   | Matrix formulation and closed form           |\n",
    "| **Polynomial Regression**           | Least squares fitting method                 |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
